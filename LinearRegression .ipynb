{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : Predict the house price in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.43.118:4043\n",
       "SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1546204496716)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.LinearRegression\n",
       "import org.apache.spark.ml.feature.VectorAssembler\n",
       "import org.apache.spark.ml.linalg.Vector\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file: String = Machine_Learning_Sections/Regression/USA_Housing.csv\n",
       "df: org.apache.spark.sql.DataFrame = [AvgAreaIncome: string, AvgAreaHouseAge: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val file =\"Machine_Learning_Sections/Regression/USA_Housing.csv\"\n",
    "var df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").format(\"csv\").load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [AvgAreaIncome: string, AvgAreaHouseAge: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Long = 5000\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AvgAreaIncome: string (nullable = true)\n",
      " |-- AvgAreaHouseAge: string (nullable = true)\n",
      " |-- AvgAreaNumberOfRooms: double (nullable = true)\n",
      " |-- AvgAreaNumberOfBedrooms: double (nullable = true)\n",
      " |-- AreaPopulation: double (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [AvgAreaIncome: double, AvgAreaHouseAge: double ... 5 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// change data type (string to double )\n",
    "df = df.selectExpr(\"cast(AvgAreaIncome as double)\",\n",
    "                   \"cast(AvgAreaHouseAge as double)\",\n",
    "                   \"AvgAreaNumberOfRooms\",\n",
    "                   \"AvgAreaNumberOfBedrooms\",\n",
    "                   \"AreaPopulation\",\n",
    "                   \"Price\",\n",
    "                   \"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AvgAreaIncome: double (nullable = true)\n",
      " |-- AvgAreaHouseAge: double (nullable = true)\n",
      " |-- AvgAreaNumberOfRooms: double (nullable = true)\n",
      " |-- AvgAreaNumberOfBedrooms: double (nullable = true)\n",
      " |-- AreaPopulation: double (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Array[String] = Array(AvgAreaIncome, AvgAreaHouseAge, AvgAreaNumberOfRooms, AvgAreaNumberOfBedrooms, AreaPopulation, Price, Address)\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1: org.apache.spark.sql.DataFrame = [label: double, AvgAreaIncome: double ... 5 more fields]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1 = df.select(df(\"Price\").as(\"label\"),\n",
    "                    $\"AvgAreaIncome\", \n",
    "                    $\"AvgAreaHouseAge\", \n",
    "                    $\"AvgAreaNumberOfRooms\",\n",
    "                    $\"AvgAreaNumberOfBedrooms\", \n",
    "                    $\"AreaPopulation\", $\"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_3365e7e6e68b\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assembler = new VectorAssembler().setInputCols(Array(\"AvgAreaIncome\",\n",
    "\t\t \"AvgAreaHouseAge\",\n",
    "\t\t \"AvgAreaNumberOfRooms\",\n",
    "\t\t \"AvgAreaNumberOfBedrooms\",\n",
    "\t\t \"AreaPopulation\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output: org.apache.spark.sql.DataFrame = [label: double, features: vector]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val output = assembler.transform(df1).select($\"label\",$\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-30 22:53:43 WARN  WeightedLeastSquares:66 - regParam is zero, which might cause numerical instability and overfitting.\n",
      "2018-12-30 22:53:43 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2018-12-30 22:53:43 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2018-12-30 22:53:44 WARN  LAPACK:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2018-12-30 22:53:44 WARN  LAPACK:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_3d3e3c0e4475\n",
       "lrModel: org.apache.spark.ml.regression.LinearRegressionModel = linReg_3d3e3c0e4475\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LinearRegression()\n",
    "val lrModel = lr.fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Msummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@ce6303a\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Msummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[Double] = Array(0.0, 0.0, 0.0, 0.20711882640369517, 0.0, 0.0)\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Msummary.pValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+\n",
      "|             label|            features|        prediction|\n",
      "+------------------+--------------------+------------------+\n",
      "|1059033.5578701235|[79545.4585743167...|1223847.0427535456|\n",
      "|  1505890.91484695|[79248.6424548256...|1494937.6916173412|\n",
      "|1058987.9878760849|[61287.0671786567...|1253016.7460814407|\n",
      "|1260616.8066294468|[63345.2400462279...|1121224.0676507396|\n",
      "| 630943.4893385402|[59982.1972257080...| 845388.7662952547|\n",
      "+------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Msummary.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Double = 0.9180238195089548\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Msummary.r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
