{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object: Predict the house price in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.43.118:4040\n",
       "SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1546201001437)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
       "import org.apache.spark.ml.regression.LinearRegression\n",
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
       "import org.apache.log4j._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "import org.apache.log4j._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file: String = Machine_Learning_Sections/Regression/USA_Housing.csv\n",
       "df: org.apache.spark.sql.DataFrame = [AvgAreaIncome: string, AvgAreaHouseAge: string ... 5 more fields]\n",
       "columnsNames: Array[String] = Array(AvgAreaIncome, AvgAreaHouseAge, AvgAreaNumberOfRooms, AvgAreaNumberOfBedrooms, AreaPopulation, Price, Address)\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "val file =\"Machine_Learning_Sections/Regression/USA_Housing.csv\"\n",
    "var df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").format(\"csv\").load(file)\n",
    "val columnsNames = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Array[String] = Array(AvgAreaIncome, AvgAreaHouseAge, AvgAreaNumberOfRooms, AvgAreaNumberOfBedrooms, AreaPopulation, Price, Address)\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AvgAreaIncome: string (nullable = true)\n",
      " |-- AvgAreaHouseAge: string (nullable = true)\n",
      " |-- AvgAreaNumberOfRooms: double (nullable = true)\n",
      " |-- AvgAreaNumberOfBedrooms: double (nullable = true)\n",
      " |-- AreaPopulation: double (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [AvgAreaIncome: double, AvgAreaHouseAge: double ... 5 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// chang de type\n",
    "df = df.selectExpr(\"cast(\"+columnsNames(0).toString+ \" as double)\",\n",
    "\"cast(\"+columnsNames(1).toString+ \" as double)\",\n",
    "\"cast(\"+columnsNames(2).toString+ \" as double)\",\n",
    "\"cast(\"+columnsNames(3).toString+ \" as double)\",\n",
    "\"cast(\"+columnsNames(4).toString+ \" as double)\",\n",
    "\"cast(\"+columnsNames(5).toString+ \" as double)\",\n",
    "\"cast(\"+columnsNames(6).toString+ \" as string)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AvgAreaIncome: double (nullable = true)\n",
      " |-- AvgAreaHouseAge: double (nullable = true)\n",
      " |-- AvgAreaNumberOfRooms: double (nullable = true)\n",
      " |-- AvgAreaNumberOfBedrooms: double (nullable = true)\n",
      " |-- AreaPopulation: double (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.VectorAssembler\n",
       "import org.apache.spark.ml.linalg.Vector\n",
       "df1: org.apache.spark.sql.DataFrame = [label: double, AvgAreaIncome: double ... 5 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "\n",
    "val df1 = df.select(df(\"Price\").as(\"label\"),\n",
    "                    $\"AvgAreaIncome\",\n",
    "                    $\"AvgAreaHouseAge\",\n",
    "                    $\"AvgAreaNumberofRooms\",\n",
    "                    $\"AvgAreaNumberofBedrooms\",\n",
    "                    $\"AreaPopulation\",\n",
    "                    $\"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- AvgAreaIncome: double (nullable = true)\n",
      " |-- AvgAreaHouseAge: double (nullable = true)\n",
      " |-- AvgAreaNumberofRooms: double (nullable = true)\n",
      " |-- AvgAreaNumberofBedrooms: double (nullable = true)\n",
      " |-- AreaPopulation: double (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res12: Long = 10000\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res17: Long = 5000\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(row => row.anyNull).count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [label: double, AvgAreaIncome: double ... 5 more fields]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_8f2547fcc665\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assembler = new VectorAssembler().setInputCols(Array(\"AvgAreaIncome\",\n",
    "\t\t \"AvgAreaHouseAge\",\n",
    "\t\t \"AvgAreaNumberofRooms\",\n",
    "\t\t \"AvgAreaNumberofBedrooms\",\n",
    "\t\t \"AreaPopulation\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output: org.apache.spark.sql.DataFrame = [label: double, features: vector]\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val output = assembler.transform(df).select($\"label\",$\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_cc5ea58ae11f\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-30 21:42:50 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2018-12-30 21:42:50 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2018-12-30 21:42:51 WARN  LAPACK:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2018-12-30 21:42:51 WARN  LAPACK:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lrModel: org.apache.spark.ml.regression.LinearRegressionModel = linReg_cc5ea58ae11f\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lrModel = lr.fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [21.578049448352026,165637.02694091276,120659.94881629614,1651.1390539904344,15.200743923741493]\n"
     ]
    }
   ],
   "source": [
    "// Print the coefficients\n",
    "println(s\"Coefficients: ${lrModel.coefficients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -2637299.033328577\n"
     ]
    }
   ],
   "source": [
    "//intercept for linear regression\n",
    "println(s\"Intercept: ${lrModel.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainingSummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@3ec5d0e1\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+\n",
      "|             label|            features|        prediction|\n",
      "+------------------+--------------------+------------------+\n",
      "|1059033.5578701235|[79545.4585743167...|1223847.0427535456|\n",
      "|  1505890.91484695|[79248.6424548256...|1494937.6916173412|\n",
      "|1058987.9878760849|[61287.0671786567...|1253016.7460814407|\n",
      "|1260616.8066294468|[63345.2400462279...|1121224.0676507396|\n",
      "| 630943.4893385402|[59982.1972257080...| 845388.7662952547|\n",
      "|1068138.0743935304|[80175.7541594853...| 1068839.155724872|\n",
      "|1502055.8173744078|[64698.4634278877...| 1670159.612035254|\n",
      "|1573936.5644777215|[78394.3392775308...|1569962.3467741245|\n",
      "+------------------+--------------------+------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingSummary.predictions.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res23: Double = 0.9180238195089548\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Coeff deter\n",
    "trainingSummary.r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
