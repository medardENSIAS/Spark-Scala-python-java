{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif: Titanic survived Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.log4j._\n",
       "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer, OneHotEncoder}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.log4j._\n",
    "import org.apache.spark.ml.feature.{VectorAssembler,StringIndexer,VectorIndexer,OneHotEncoder}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "file: String = Machine_Learning_Sections/Classification/titanic.csv\n",
       "df: org.apache.spark.sql.DataFrame = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "val file =\"Machine_Learning_Sections/Classification/titanic.csv\"\n",
    "val df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").format(\"csv\").load(file)\n",
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "logregdataall: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\n",
       "logregdata: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val logregdataall = df.select(df(\"Survived\").as(\"label\"), $\"Pclass\", $\"Sex\", $\"Age\", $\"SibSp\", $\"Parch\", $\"Fare\", $\"Embarked\")\n",
    "val logregdata = logregdataall.na.drop()\n",
    "logregdata.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genderIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_b18adc6cab7d\n",
       "embarkIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_79fa96eb557c\n",
       "genderEncoder: org.apache.spark.ml.feature.OneHotEncoder = oneHot_c2917011ec1d\n",
       "embarkEncoder: org.apache.spark.ml.feature.OneHotEncoder = oneHot_2792bf45c188\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val genderIndexer = new StringIndexer().setInputCol(\"Sex\").setOutputCol(\"SexIndex\")\n",
    "val embarkIndexer = new StringIndexer().setInputCol(\"Embarked\").setOutputCol(\"EmbarkIndex\")\n",
    "\n",
    "val genderEncoder = new OneHotEncoder().setInputCol(\"SexIndex\").setOutputCol(\"SexVec\")\n",
    "val embarkEncoder = new OneHotEncoder().setInputCol(\"EmbarkIndex\").setOutputCol(\"EmbarkVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_2f580c9a532b\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assembler = (new VectorAssembler()\n",
    "                  .setInputCols(Array(\"Pclass\", \"SexVec\", \"Age\",\"SibSp\",\"Parch\",\"Fare\",\"EmbarkVec\"))\n",
    "                  .setOutputCol(\"features\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Pclass: int ... 6 more fields]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Pclass: int ... 6 more fields]\n",
       "res14: Long = 524\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(training, test) = logregdata.randomSplit(Array(0.75, 0.25), seed = 12345)\n",
    "training.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res15: Long = 312\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.filter($\"label\"=== 0).count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res16: Long = 212\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.filter($\"label\"=== 1).count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Pipeline\n",
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_2ff6bf6ace4b\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_2f92f80e12f0\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "val lr = new LogisticRegression()\n",
    "val pipeline = \n",
    "new Pipeline().setStages(Array(genderIndexer,embarkIndexer,genderEncoder,embarkEncoder,assembler, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.PipelineModel = pipeline_2f92f80e12f0\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 14 more fields]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res19: Long = 188\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       1.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       1.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       1.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       0.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       1.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "|       0.0|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select($\"prediction\",$\"label\").show(188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[171] at rdd at <console>:62\n",
       "metrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@6f4b369\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prediction = results.select($\"prediction\",$\"label\").as[(Double, Double)].rdd\n",
    "val metrics = new MulticlassMetrics(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res24: Double = 0.8191489361702128\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// prediction accuracy \n",
    "metrics.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res26: org.apache.spark.mllib.linalg.Matrix =\n",
       "100.0  12.0\n",
       "22.0   54.0\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// confusion Matrix\n",
    "metrics.confusionMatrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
